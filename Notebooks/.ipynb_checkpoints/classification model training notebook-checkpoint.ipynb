{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")                     #Ignoring unnecessory warnings\n",
    "\n",
    "import numpy as np                                  #for large and multi-dimensional arrays\n",
    "import pandas as pd                                 #for data manipulation and analysis\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from gensim.models import Word2Vec                                   #For Word2Vec\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cv_txt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Your Name November 13, 2019 Short description ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Last Updated on 21st June 2019 Debarghya Das d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DougHeffernan Passionate Driver EDUCATION Marc...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jon Snow HOUSE Stark REALM Kingdom of The Nort...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Experience Sep/2015 Present Job 4 Employer, Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             cv_txt  score\n",
       "0           0  Your Name November 13, 2019 Short description ...      7\n",
       "1           1  Last Updated on 21st June 2019 Debarghya Das d...      6\n",
       "2           2  DougHeffernan Passionate Driver EDUCATION Marc...      9\n",
       "3           3  Jon Snow HOUSE Stark REALM Kingdom of The Nort...      9\n",
       "4           4  Experience Sep/2015 Present Job 4 Employer, Co...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "pd.pandas.set_option('display.max_rows',None)\n",
    "df = pd.read_csv('resume_data2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Basic Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_txt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your Name November 13, 2019 Short description ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last Updated on 21st June 2019 Debarghya Das d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DougHeffernan Passionate Driver EDUCATION Marc...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jon Snow HOUSE Stark REALM Kingdom of The Nort...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experience Sep/2015 Present Job 4 Employer, Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              cv_txt  score\n",
       "0  Your Name November 13, 2019 Short description ...      7\n",
       "1  Last Updated on 21st June 2019 Debarghya Das d...      6\n",
       "2  DougHeffernan Passionate Driver EDUCATION Marc...      9\n",
       "3  Jon Snow HOUSE Stark REALM Kingdom of The Nort...      9\n",
       "4  Experience Sep/2015 Present Job 4 Employer, Co...      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_txt    0\n",
       "score     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Updated on 21st June 2019 Debarghya Das debarghyadas.com| fb.co/dd deedy@fb.com | 607.379.5733 | dd367@cornell.edu EDUCATION CORNELL UNIVERSITY MENG IN COMPUTER SCIENCE Dec 2014 | Ithaca, NY CORNELL UNIVERSITY BS IN COMPUTER SCIENCE May 2014 | Ithaca, NY College of Engineering Magna Cum Laude Cum. GPA: 3.83 / 4.0 Major GPA: 3.9 / 4.0 LA MARTINIERE FOR BOYS Grad. May 2011| Kolkata, India LINKS Facebook:// dd Github:// deedydas LinkedIn:// debarghyadas YouTube:// DeedyDash007 Twitter:// @debarghya_das Quora:// Debarghya-Das COURSEWORK GRADUATE Advanced Machine Learning Open Source Software Engineering Advanced Interactive Graphics Compilers + Practicum Cloud Computing Evolutionary Computation Defending Computer Networks Machine Learning UNDERGRADUATE Information Retrieval Operating Systems Artificial Intelligence + Practicum Functional Programming Computer Graphics + Practicum (Research Asst. & Teaching Asst 2x) Unix Tools and Scripting SKILLS PROGRAMMING Over 5000 lines: Java • Shell • Python • Javascript OCaml • Matlab • Rails • LATEX Over 1000 lines: C • C++ • CSS • PHP • Assembly Familiar: AS3 • iOS • Android • MySQL EXPERIENCE FACEBOOK | SOFTWARE ENGINEER Jan 2015 - Present | New York, NY COURSERA | KPCB FELLOW + SOFTWARE ENGINEERING INTERN June 2014 – Sep 2014 | Mountain View, CA • 52 out of 2500 applicants chosen to be a KPCB Fellow 2014. • Led and shipped Yoda - the admin interface for the new Phoenix platform. • Full-stack developer - Wrote and reviewed code for JS using Backbone, Jade, Stylus and Require and Scala using Play GOOGLE | SOFTWARE ENGINEERING INTERN May 2013 – Aug 2013 | Mountain View, CA • Worked on the YouTube Captions team, in Javascript and Python to plan, to design and develop the full stack to add and edit Automatic Speech Recognition captions. In production. • Created a backbone.js-like framework for the Captions editor. PHABRICATOR | OPEN SOURCE CONTRIBUTOR & TEAM LEADER Jan 2013 – May 2013 | Palo Alto, CA & Ithaca, NY • Phabricator is used daily by Facebook, Dropbox, Quora, Asana and more. • I created the Meme generator and more in PHP and Shell. • Led a team from MIT, Cornell, IC London and UHelsinki for the project. RESEARCH CORNELL ROBOT LEARNING LAB | RESEARCHER Jan 2014 – Jan 2015 | Ithaca, NY Worked with Ashesh Jain and Prof Ashutosh Saxena to create PlanIt, a tool which learns from large scale user preference feedback to plan robot trajectories in human environments. CORNELL PHONETICS LAB | HEAD UNDERGRADUATE RESEARCHER Mar 2012 – May 2013 | Ithaca, NY Led the development of QuickTongue, the first ever breakthrough tongue-controlled game with Prof Sam Tilsen to aid in Linguistics research. AWARDS 2014 top 52/2500 KPCB Engineering Fellow 2014 1st/50 Microsoft Coding Competition, Cornell 2013 National Jump Trading Challenge Finalist 2013 7th/120 CS 3410 Cache Race Bot Tournament 2012 2nd/150 CS 3110 Biannual Intra-Class Bot Tournament 2011 National Indian National Mathematics Olympiad (INMO) Finalist PUBLICATIONS [1] A. Jain, D. Das, and A. Saxena. Planit: A crowdsourcing approach for learning to plan paths from large scale preference feedback. Tech Report, ICRA, in press. [2] S. Tilsen, D. Das, and B. McKee. Real-time articulatory biofeedback with electromagnetic articulography. Linguistics Vanguard, in press. \n",
      "-----------------------------------------------------\n",
      "DougHeffernan Passionate Driver EDUCATION March, 2005 Advanced Training | internal  International Parcel Service (IPS) • Completed the IPS aptitude test for aspiring managerial staff • Subsequently decided to keep pursuing his passion for driving and delivering instead 1985 - 1986 Junior College | no degree  Nassau Community College Coursework: College Preparatory English, Introduction to College Biology I, Contemporary Music, The History of Sports in America 1980 - 1984 High School Diploma | ⌀ 1.7 GPA  St. Gregory's High School, Queens, NY Honors Classes: Physical Education, running back (All-County) EXPERIENCE 1994 - now Truck Driver | Queens Area   International Parcel Service (IPS) • Delivered packages to costumers around New York City (mostly Queens) • Practiced solidarity as a union member during a driver strike in the year 2000 • Occasionally chosen to move specialty items such as live animals between NY Zoos • Company-wide record holder for number of days without an ”incident” - no complaints or broken packages • Was profiled in the company newsletter IP-Yes May, 1999 Interim Shift Supervisor | Queens Office   International Parcel Service (IPS) • Brief detour into white collar occupation when the team was in need • Provided temporary support to the office in the absense of supervisor O´Boyle (personal leave of absense) • Scheduled routes for drivers • Managed the budget • Contributed to the motivation of all drivers and loaders 1992 - 1993 Truck Loader | Packages & Cargo   International Parcel Service (IPS) • Loaded all packages securely and in a logical order for the drivers to deliver • Worked closely with the drivers to ensure maximum efficiency and safety • Briefly returned to loading duties due to an unfortunate test-taking incident in 2002 1988 - 1991 Security Guard | Nightclub & Bar  Sour Polly, Queens, NY • Providing rigorous access control of costumers • Making difficult and critical entry decisions • Keeping the customers safe and entertained Queens, NY, May 14th, 2007 February 9, 1965 � 3121 Aberdeen Road, Queens, NY  (718) 555-LOGS � doug.heffernan@ips-nyc.com �  Skills & Strengths Driving • Save and punctual delivery of packages to end consumers • Rudimentary vehicle maintenance task People Skills • Contributes significantly to collegial athmosphere BBQ • Your steaks, your bacons, your bratwursts • Definitely no tofu! Athletics • Tried out for Nassau Rebels semi-pro football team twice Caregiving • Providing home (basement) for father-in-law for years creative problem solver keeping it light ultimate team player modest leader in spirit dependable driver Eager to deepen knowledge about... • ...baloney-darts • ...getting back into shape • ...containing cranky old people Sports Teams 5/5 4/5 5/5 4/5 -6/5 4/5 Languages English Japanese Spanish French Interests & Activities Football (watching, occasionally playing) | Rock Music | Bruce Springsteen | Good Food Bowling Cooper´s Onion Ringers since 1999 Softball  board member from 1998-1999 \n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "    print(df['cv_txt'].values[i])\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_txt    0\n",
       "score     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df['cv_txt']\n",
    "df_y = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "len(stop_words) #finding stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['cv_txt'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last updat st june debarghya das debarghyada com fb co dd deedi fb com dd cornel edu educ cornel univers meng comput scienc dec ithaca ny cornel univers bs comput scienc may ithaca ny colleg engin magna cum laud cum gpa major gpa la martinier boy grad may kolkata india link facebook dd github deedyda linkedin debarghyada youtub deedydash twitter debarghya das quora debarghya das coursework graduat advanc machin learn open sourc softwar engin advanc interact graphic compil practicum cloud comput evolutionari comput defend comput network machin learn undergradu inform retriev oper system artifici intellig practicum function program comput graphic practicum research asst teach asst x unix tool script skill program line java shell python javascript ocaml matlab rail latex line c c css php assembl familiar io android mysql experi facebook softwar engin jan present new york ny coursera kpcb fellow softwar engin intern june sep mountain view ca applic chosen kpcb fellow led ship yoda admin interfac new phoenix platform full stack develop wrote review code js use backbon jade stylus requir scala use play googl softwar engin intern may aug mountain view ca work youtub caption team javascript python plan design develop full stack add edit automat speech recognit caption product creat backbon js like framework caption editor phabric open sourc contributor team leader jan may palo alto ca ithaca ny phabric use daili facebook dropbox quora asana creat meme generat php shell led team mit cornel ic london uhelsinki project research cornel robot learn lab research jan jan ithaca ny work ashesh jain prof ashutosh saxena creat planit tool learn larg scale user prefer feedback plan robot trajectori human environ cornel phonet lab head undergradu research mar may ithaca ny led develop quicktongu first ever breakthrough tongu control game prof sam tilsen aid linguist research award top kpcb engin fellow st microsoft code competit cornel nation jump trade challeng finalist th cs cach race bot tournament nd cs biannual intra class bot tournament nation indian nation mathemat olympiad inmo finalist public jain das saxena planit crowdsourc approach learn plan path larg scale prefer feedback tech report icra press tilsen das b mckee real time articulatori biofeedback electromagnet articulographi linguist vanguard press'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size=5000\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "type(onehot_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ... 1730 4180   32]\n",
      " [   0    0    0 ... 1055 2683 2402]\n",
      " [   0    0    0 ... 4087  530  616]\n",
      " ...\n",
      " [   0    0    0 ... 1551  244 4276]\n",
      " [1645 1314 1686 ...  244  244 4276]\n",
      " [   0    0    0 ... 1647  244 4276]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=400\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 40)           200000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 400, 40)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 611ms/step - loss: -46.3091 - accuracy: 0.1020 - val_loss: -46.6244 - val_accuracy: 0.1094\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 2s 519ms/step - loss: -48.3868 - accuracy: 0.1020 - val_loss: -48.7969 - val_accuracy: 0.1094\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 2s 544ms/step - loss: -50.5598 - accuracy: 0.1020 - val_loss: -50.8603 - val_accuracy: 0.1094\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 2s 520ms/step - loss: -52.7137 - accuracy: 0.1020 - val_loss: -52.8727 - val_accuracy: 0.1094\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 3s 634ms/step - loss: -54.9985 - accuracy: 0.1020 - val_loss: -54.7651 - val_accuracy: 0.1094\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 2s 530ms/step - loss: -56.8089 - accuracy: 0.1020 - val_loss: -56.5599 - val_accuracy: 0.1094\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 2s 566ms/step - loss: -58.4549 - accuracy: 0.1020 - val_loss: -58.2650 - val_accuracy: 0.1094\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 3s 678ms/step - loss: -61.0506 - accuracy: 0.1020 - val_loss: -59.9366 - val_accuracy: 0.1094\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 2s 615ms/step - loss: -61.7713 - accuracy: 0.1020 - val_loss: -61.5751 - val_accuracy: 0.1094\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 2s 625ms/step - loss: -64.0513 - accuracy: 0.1020 - val_loss: -63.1913 - val_accuracy: 0.1094\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 3s 635ms/step - loss: -65.0146 - accuracy: 0.1020 - val_loss: -64.7642 - val_accuracy: 0.1094\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 3s 638ms/step - loss: -67.1630 - accuracy: 0.1020 - val_loss: -66.3328 - val_accuracy: 0.1094\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 2s 590ms/step - loss: -67.9706 - accuracy: 0.1020 - val_loss: -67.8515 - val_accuracy: 0.1094\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 3s 649ms/step - loss: -69.5245 - accuracy: 0.1020 - val_loss: -69.3874 - val_accuracy: 0.1094\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 2s 572ms/step - loss: -70.8560 - accuracy: 0.1020 - val_loss: -70.9155 - val_accuracy: 0.1094\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 2s 617ms/step - loss: -73.5927 - accuracy: 0.1020 - val_loss: -72.4228 - val_accuracy: 0.1094\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 2s 580ms/step - loss: -74.0576 - accuracy: 0.1020 - val_loss: -73.9384 - val_accuracy: 0.1094\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 3s 667ms/step - loss: -75.8880 - accuracy: 0.1020 - val_loss: -75.4372 - val_accuracy: 0.1094\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 2s 600ms/step - loss: -77.2198 - accuracy: 0.1020 - val_loss: -76.9385 - val_accuracy: 0.1094\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 2s 612ms/step - loss: -79.1817 - accuracy: 0.1020 - val_loss: -78.4453 - val_accuracy: 0.1094\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 2s 619ms/step - loss: -80.0703 - accuracy: 0.1020 - val_loss: -79.9599 - val_accuracy: 0.1094\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 2s 603ms/step - loss: -83.3171 - accuracy: 0.1020 - val_loss: -81.4534 - val_accuracy: 0.1094\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 3s 647ms/step - loss: -83.7021 - accuracy: 0.1020 - val_loss: -82.9289 - val_accuracy: 0.1094\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 3s 675ms/step - loss: -85.7571 - accuracy: 0.1020 - val_loss: -84.4067 - val_accuracy: 0.1094\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 3s 743ms/step - loss: -86.7934 - accuracy: 0.1020 - val_loss: -85.8781 - val_accuracy: 0.1094\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 2s 594ms/step - loss: -88.0754 - accuracy: 0.1020 - val_loss: -87.3284 - val_accuracy: 0.1094\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 2s 587ms/step - loss: -89.1287 - accuracy: 0.1020 - val_loss: -88.7803 - val_accuracy: 0.1094\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 2s 556ms/step - loss: -91.0331 - accuracy: 0.1020 - val_loss: -90.2300 - val_accuracy: 0.1094\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 2s 605ms/step - loss: -93.9298 - accuracy: 0.1020 - val_loss: -91.6666 - val_accuracy: 0.1094\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 2s 561ms/step - loss: -94.5145 - accuracy: 0.1020 - val_loss: -93.1043 - val_accuracy: 0.1094\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 2s 571ms/step - loss: -96.1667 - accuracy: 0.1020 - val_loss: -94.5534 - val_accuracy: 0.1094\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 2s 555ms/step - loss: -97.8732 - accuracy: 0.1020 - val_loss: -95.9910 - val_accuracy: 0.1094\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 2s 589ms/step - loss: -98.2464 - accuracy: 0.1020 - val_loss: -97.4123 - val_accuracy: 0.1094\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 2s 558ms/step - loss: -99.6337 - accuracy: 0.1020 - val_loss: -98.8414 - val_accuracy: 0.1094\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 2s 579ms/step - loss: -101.7342 - accuracy: 0.1020 - val_loss: -100.2700 - val_accuracy: 0.1094\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 2s 557ms/step - loss: -103.0547 - accuracy: 0.1020 - val_loss: -101.6741 - val_accuracy: 0.1094\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 2s 610ms/step - loss: -104.0765 - accuracy: 0.1020 - val_loss: -103.0903 - val_accuracy: 0.1094\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 3s 636ms/step - loss: -105.7448 - accuracy: 0.1020 - val_loss: -104.4975 - val_accuracy: 0.1094\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 2s 624ms/step - loss: -108.0765 - accuracy: 0.1020 - val_loss: -105.9063 - val_accuracy: 0.1094\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 2s 563ms/step - loss: -109.2088 - accuracy: 0.1020 - val_loss: -107.2975 - val_accuracy: 0.1094\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 3s 631ms/step - loss: -109.7319 - accuracy: 0.1020 - val_loss: -108.6897 - val_accuracy: 0.1094\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 2s 608ms/step - loss: -112.3104 - accuracy: 0.1020 - val_loss: -110.0871 - val_accuracy: 0.1094\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 2s 576ms/step - loss: -113.7392 - accuracy: 0.1020 - val_loss: -111.4866 - val_accuracy: 0.1094\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 2s 581ms/step - loss: -114.8638 - accuracy: 0.1020 - val_loss: -112.8802 - val_accuracy: 0.1094\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 2s 575ms/step - loss: -116.6323 - accuracy: 0.1020 - val_loss: -114.2715 - val_accuracy: 0.1094\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 2s 624ms/step - loss: -117.8433 - accuracy: 0.1020 - val_loss: -115.6760 - val_accuracy: 0.1094\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 2s 562ms/step - loss: -118.3289 - accuracy: 0.1020 - val_loss: -117.0730 - val_accuracy: 0.1094\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 2s 565ms/step - loss: -120.0476 - accuracy: 0.1020 - val_loss: -118.4560 - val_accuracy: 0.1094\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 2s 561ms/step - loss: -122.5570 - accuracy: 0.1020 - val_loss: -119.8456 - val_accuracy: 0.1094\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 3s 690ms/step - loss: -123.0122 - accuracy: 0.1020 - val_loss: -121.2344 - val_accuracy: 0.1094\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 2s 611ms/step - loss: -124.3600 - accuracy: 0.1020 - val_loss: -122.6060 - val_accuracy: 0.1094\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 3s 712ms/step - loss: -127.4976 - accuracy: 0.1020 - val_loss: -123.9900 - val_accuracy: 0.1094\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 3s 831ms/step - loss: -128.5877 - accuracy: 0.1020 - val_loss: -125.3777 - val_accuracy: 0.1094\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 3s 702ms/step - loss: -129.5526 - accuracy: 0.1020 - val_loss: -126.7619 - val_accuracy: 0.1094\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 3s 738ms/step - loss: -131.1774 - accuracy: 0.1020 - val_loss: -128.1428 - val_accuracy: 0.1094\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 3s 720ms/step - loss: -131.2066 - accuracy: 0.1020 - val_loss: -129.5187 - val_accuracy: 0.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "4/4 [==============================] - 2s 593ms/step - loss: -132.5866 - accuracy: 0.1020 - val_loss: -130.8970 - val_accuracy: 0.1094\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 2s 615ms/step - loss: -132.9069 - accuracy: 0.1020 - val_loss: -132.2606 - val_accuracy: 0.1094\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 3s 684ms/step - loss: -135.4856 - accuracy: 0.1020 - val_loss: -133.6174 - val_accuracy: 0.1094\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 3s 805ms/step - loss: -137.6893 - accuracy: 0.1020 - val_loss: -134.9874 - val_accuracy: 0.1094\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 2s 602ms/step - loss: -138.4461 - accuracy: 0.1020 - val_loss: -136.3597 - val_accuracy: 0.1094\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 2s 610ms/step - loss: -139.3759 - accuracy: 0.1020 - val_loss: -137.7312 - val_accuracy: 0.1094\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 2s 576ms/step - loss: -142.2977 - accuracy: 0.1020 - val_loss: -139.0827 - val_accuracy: 0.1094\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 2s 590ms/step - loss: -142.6428 - accuracy: 0.1020 - val_loss: -140.4498 - val_accuracy: 0.1094\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 3s 629ms/step - loss: -144.3045 - accuracy: 0.1020 - val_loss: -141.8036 - val_accuracy: 0.1094\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 2s 606ms/step - loss: -146.4097 - accuracy: 0.1020 - val_loss: -143.1669 - val_accuracy: 0.1094\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 3s 673ms/step - loss: -146.8904 - accuracy: 0.1020 - val_loss: -144.5316 - val_accuracy: 0.1094\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 2s 536ms/step - loss: -148.0528 - accuracy: 0.1020 - val_loss: -145.8961 - val_accuracy: 0.1094\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 2s 583ms/step - loss: -149.5098 - accuracy: 0.1020 - val_loss: -147.2458 - val_accuracy: 0.1094\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 2s 544ms/step - loss: -149.8831 - accuracy: 0.1020 - val_loss: -148.6012 - val_accuracy: 0.1094\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 2s 598ms/step - loss: -152.8379 - accuracy: 0.1020 - val_loss: -149.9671 - val_accuracy: 0.1094\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 2s 532ms/step - loss: -154.9726 - accuracy: 0.1020 - val_loss: -151.3173 - val_accuracy: 0.1094\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 2s 593ms/step - loss: -154.6913 - accuracy: 0.1020 - val_loss: -152.6729 - val_accuracy: 0.1094\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 2s 532ms/step - loss: -157.6419 - accuracy: 0.1020 - val_loss: -154.0298 - val_accuracy: 0.1094\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 2s 592ms/step - loss: -159.5061 - accuracy: 0.1020 - val_loss: -155.3839 - val_accuracy: 0.1094\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 2s 539ms/step - loss: -159.4568 - accuracy: 0.1020 - val_loss: -156.7413 - val_accuracy: 0.1094\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 2s 599ms/step - loss: -160.9652 - accuracy: 0.1020 - val_loss: -158.0995 - val_accuracy: 0.1094\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 2s 533ms/step - loss: -161.6451 - accuracy: 0.1020 - val_loss: -159.4579 - val_accuracy: 0.1094\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 2s 596ms/step - loss: -162.7414 - accuracy: 0.1020 - val_loss: -160.7985 - val_accuracy: 0.1094\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 2s 534ms/step - loss: -164.5095 - accuracy: 0.1020 - val_loss: -162.1350 - val_accuracy: 0.1094\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 2s 598ms/step - loss: -164.9468 - accuracy: 0.1020 - val_loss: -163.4789 - val_accuracy: 0.1094\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 2s 543ms/step - loss: -168.2708 - accuracy: 0.1020 - val_loss: -164.8335 - val_accuracy: 0.1094\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 2s 589ms/step - loss: -168.4128 - accuracy: 0.1020 - val_loss: -166.1789 - val_accuracy: 0.1094\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 2s 532ms/step - loss: -169.5794 - accuracy: 0.1020 - val_loss: -167.5129 - val_accuracy: 0.1094\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 2s 583ms/step - loss: -173.3778 - accuracy: 0.1020 - val_loss: -168.8726 - val_accuracy: 0.1094\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 2s 536ms/step - loss: -174.2135 - accuracy: 0.1020 - val_loss: -170.2151 - val_accuracy: 0.1094\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 3s 626ms/step - loss: -175.2147 - accuracy: 0.1020 - val_loss: -171.5490 - val_accuracy: 0.1094\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 2s 612ms/step - loss: -176.0010 - accuracy: 0.1020 - val_loss: -172.9023 - val_accuracy: 0.1094\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 3s 724ms/step - loss: -176.3309 - accuracy: 0.1020 - val_loss: -174.2505 - val_accuracy: 0.1094\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 3s 687ms/step - loss: -178.9820 - accuracy: 0.1020 - val_loss: -175.5910 - val_accuracy: 0.1094\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 2s 604ms/step - loss: -180.6477 - accuracy: 0.1020 - val_loss: -176.9295 - val_accuracy: 0.1094\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 3s 642ms/step - loss: -180.9695 - accuracy: 0.1020 - val_loss: -178.2613 - val_accuracy: 0.1094\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 2s 580ms/step - loss: -183.1976 - accuracy: 0.1020 - val_loss: -179.6180 - val_accuracy: 0.1094\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 2s 589ms/step - loss: -185.0932 - accuracy: 0.1020 - val_loss: -180.9596 - val_accuracy: 0.1094\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 2s 533ms/step - loss: -185.6860 - accuracy: 0.1020 - val_loss: -182.3025 - val_accuracy: 0.1094\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 2s 620ms/step - loss: -187.5057 - accuracy: 0.1020 - val_loss: -183.6519 - val_accuracy: 0.1094\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 3s 659ms/step - loss: -186.8765 - accuracy: 0.1020 - val_loss: -184.9966 - val_accuracy: 0.1094\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 3s 709ms/step - loss: -189.9252 - accuracy: 0.1020 - val_loss: -186.3587 - val_accuracy: 0.1094\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 3s 687ms/step - loss: -192.4431 - accuracy: 0.1020 - val_loss: -187.7266 - val_accuracy: 0.1094\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 3s 657ms/step - loss: -191.8241 - accuracy: 0.1020 - val_loss: -189.1482 - val_accuracy: 0.1094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282f316fe10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are feeding the \n",
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.109375"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,y_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3477)\t0.03451900530181986\n",
      "  (0, 4644)\t0.04553529853589914\n",
      "  (0, 2397)\t0.08365062460886882\n",
      "  (0, 3075)\t0.04720353200871461\n",
      "  (0, 4332)\t0.04412482723197255\n",
      "  (0, 1253)\t0.04720353200871461\n",
      "  (0, 1207)\t0.030508993769107727\n",
      "  (0, 3178)\t0.04412482723197255\n",
      "  (0, 2677)\t0.04412482723197255\n",
      "  (0, 1820)\t0.0882496544639451\n",
      "  (0, 4786)\t0.09440706401742922\n",
      "  (0, 2804)\t0.09440706401742922\n",
      "  (0, 1490)\t0.0882496544639451\n",
      "  (0, 4989)\t0.04412482723197255\n",
      "  (0, 2897)\t0.03998918509561814\n",
      "  (0, 2237)\t0.04086126865526724\n",
      "  (0, 3421)\t0.03919303518245176\n",
      "  (0, 3977)\t0.03324019025330949\n",
      "  (0, 258)\t0.037782563878525174\n",
      "  (0, 2997)\t0.02305628441298117\n",
      "  (0, 741)\t0.04086126865526724\n",
      "  (0, 4023)\t0.10680458462718473\n",
      "  (0, 4063)\t0.04553529853589914\n",
      "  (0, 2990)\t0.06814515529412091\n",
      "  (0, 2547)\t0.06648038050661897\n",
      "  :\t:\n",
      "  (0, 1000)\t0.07997837019123628\n",
      "  (0, 2553)\t0.035483048950987035\n",
      "  (0, 1482)\t0.08648703679197389\n",
      "  (0, 775)\t0.013359417434252\n",
      "  (0, 2676)\t0.10327832007982579\n",
      "  (0, 2946)\t0.2509518738266065\n",
      "  (0, 2223)\t0.2462264238368193\n",
      "  (0, 1118)\t0.031773062719522314\n",
      "  (0, 3759)\t0.0381770720252551\n",
      "  (0, 846)\t0.1039319431338827\n",
      "  (0, 1408)\t0.038460648258251226\n",
      "  (0, 936)\t0.34471699337154704\n",
      "  (0, 1096)\t0.12258380596580172\n",
      "  (0, 749)\t0.01266194070840155\n",
      "  (0, 1688)\t0.0882496544639451\n",
      "  (0, 780)\t0.019664872681763663\n",
      "  (0, 1044)\t0.22767649267949572\n",
      "  (0, 2294)\t0.04052411402420102\n",
      "  (0, 4125)\t0.05987387102141208\n",
      "  (0, 4680)\t0.02560183148382079\n",
      "  (0, 2402)\t0.03600604568761869\n",
      "  (0, 332)\t0.023187940668397387\n",
      "  (0, 1753)\t0.028176741948372476\n",
      "  (0, 4660)\t0.02987500573725461\n",
      "  (0, 1409)\t0.010177758526163367\n"
     ]
    }
   ],
   "source": [
    "final_tf = df_x\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1,2),max_features=5000)\n",
    "tf_data = tf_idf.fit_transform(final_tf)\n",
    "print(tf_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tf_idf, open(\"tfidf_vectorizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pickle.load(open('tfidf_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 5000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'ab',\n",
       " 'abap',\n",
       " 'abap kolkata',\n",
       " 'abc',\n",
       " 'abil',\n",
       " 'abil quick',\n",
       " 'abil work',\n",
       " 'abl',\n",
       " 'abroad']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tf_idf.get_feature_names()\n",
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "df_y1 = encode.fit_transform(df_y)\n",
    "type(df_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(['df_y1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED =42\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(tf_data,df_y,test_size = 0.2,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB().fit(x_train, y_train)\n",
    "\n",
    "y_pred_nb=nb_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_val, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train,y_train)\n",
    "y_pred_rf = rf_model.predict(x_val)\n",
    "accuracy_score(y_val,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_model,open('rf_score_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING WITH SOME DATE\n",
    "test = 'last updat st june debarghya das debarghyada com fb co dd deedi fb com dd cornel edu educ cornel univers meng comput scienc dec ithaca ny cornel univers bs comput scienc may ithaca ny colleg engin magna cum laud cum gpa major gpa la martinier boy grad may kolkata india link facebook dd github deedyda linkedin debarghyada youtub deedydash twitter debarghya das quora debarghya das coursework graduat advanc machin learn open sourc softwar engin advanc interact graphic compil practicum cloud comput evolutionari comput defend comput network machin learn undergradu inform retriev oper system artifici intellig practicum function program comput graphic practicum research asst teach asst x unix tool script skill program line java shell python javascript ocaml matlab rail latex line c c css php assembl familiar io android mysql experi facebook softwar engin jan present new york ny coursera kpcb fellow softwar engin intern june sep mountain view ca applic chosen kpcb fellow led ship yoda admin interfac new phoenix platform full stack develop wrote review code js use backbon jade stylus requir scala use play googl softwar engin intern may aug mountain view ca work youtub caption team javascript python plan design develop full stack add edit automat speech recognit caption product creat backbon js like framework caption editor phabric open sourc contributor team leader jan may palo alto ca ithaca ny phabric use daili facebook dropbox quora asana creat meme generat php shell led team mit cornel ic london uhelsinki project research cornel robot learn lab research jan jan ithaca ny work ashesh jain prof ashutosh saxena creat planit tool learn larg scale user prefer feedback plan robot trajectori human environ cornel phonet lab head undergradu research mar may ithaca ny led develop quicktongu first ever breakthrough tongu control game prof sam tilsen aid linguist research award top kpcb engin fellow st microsoft code competit cornel nation jump trade challeng finalist th cs cach race bot tournament nd cs biannual intra class bot tournament nation indian nation mathemat olympiad inmo finalist public jain das saxena planit crowdsourc approach learn plan path larg scale prefer feedback tech report icra press tilsen das b mckee real time articulatori biofeedback electromagnet articulographi linguist vanguard press'\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "corpus_test = []\n",
    "# for i in range(0, len(df)):\n",
    "review = re.sub('[^a-zA-Z]', ' ', test)\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "    \n",
    "review = [snow.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "review = ' '.join(review)\n",
    "corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tf_test = corpus_test\n",
    "# tf_idf_test = TfidfVectorizer(ngram_range=(1,2),max_features=5000)\n",
    "tf_data_test = v.transform(final_tf_test)\n",
    "tf_data_test.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('rf_score_model.pkl', 'rb'))\n",
    "result = loaded_model.predict(tf_data_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rf with rscv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False, total=   6.0s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False, total=   6.1s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False, total=   7.5s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False, total=   6.5s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=110, bootstrap=False, total=   6.4s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=   7.1s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=   9.2s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=   6.8s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=   7.1s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=   7.1s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   6.0s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.8s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   5.8s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   9.4s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   5.2s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.2s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.2s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.1s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.2s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.5s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.1s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.1s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.3s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.0s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5, n_jobs=1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "cls_rf_rscv = RandomForestClassifier()\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(cls_rf_rscv, random_grid,n_iter=5, n_jobs=1, cv=5,verbose=2)\n",
    "random_search_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, max_features='sqrt', min_samples_split=10,\n",
       "                       n_estimators=2000, random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators= 2000,\n",
    "                                     min_samples_split= 10,\n",
    "                                     min_samples_leaf= 1,\n",
    "                                     max_features= 'sqrt',\n",
    "                                     max_depth= 90,\n",
    "                                     bootstrap= True,\n",
    "                                    random_state = SEED)\n",
    "base_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rscv = base_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred_rf_rscv = rf_rscv_model.predict(x_val)\n",
    "accuracy_score(y_val,y_pred_rf_rscv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
